# Retail-Sales-Analytics-PySpark-PowerBI
End-to-end Retail Sales Analytics project using Python (PySpark) for big-data processing and Power BI for executive dashboards. Includes data cleaning, transformation, business analysis, window functions, optimization with Parquet, and visualization.

ğŸ¢ Business Problem

Retail leadership needs answers to:

Which regions drive the most revenue?

Which categories are profitable or loss-making?

How do discounts impact profit?

Who are the top customers?

Are sales increasing or declining over time?

ğŸ› ï¸ Tech Stack

PySpark â€“ Big data processing & analytics

Apache Spark â€“ Distributed computing

Power BI â€“ Business intelligence & dashboards

Python â€“ Data logic

Parquet â€“ Optimized data storage

VS Code â€“ Development environment

ğŸ§± Project Architecture
Raw CSV
   â†“
Data Cleaning (PySpark)
   â†“
Data Transformation & Feature Engineering
   â†“
Business Analysis & KPIs
   â†“
Window Functions (Advanced Analytics)
   â†“
Optimization & Parquet Storage
   â†“
Power BI Dashboard

ğŸ”¢ STEP-BY-STEP PROJECT FLOW
ğŸŸ¢ STEP 1: Data Ingestion

Load raw retail CSV data using PySpark

Infer schema and validate row counts

ğŸ“‚ Notebook:

notebooks/01_data_ingestion.ipynb

ğŸŸ¢ STEP 2: Data Cleaning & Validation

Remove duplicates

Handle null values

Enforce business rules (Sales > 0, Quantity > 0)

Validate row counts before & after cleaning

ğŸ“‚ Notebook:

notebooks/02_data_cleaning.ipynb

ğŸŸ¢ STEP 3: Data Transformation

Create Year & Month columns

Calculate Profit Margin

Create Discount Bands

Classify Customer Types

ğŸ“‚ Notebook:

notebooks/03_data_transformation.ipynb

ğŸŸ¢ STEP 4: Business Analysis

Revenue by Region

Profit by Category

Discount impact analysis

Customer segmentation

Monthly sales trends

ğŸ“‚ Notebook:

notebooks/04_business_analysis.ipynb

ğŸŸ¢ STEP 5: Window Functions (Advanced)

Rank customers by sales

Running total of monthly sales

Product ranking by profit

Contribution percentage analysis

ğŸ“‚ Notebook:

notebooks/05_window_functions.ipynb

ğŸŸ¢ STEP 6: Optimization & Parquet

Repartition data

Store analytics-ready data in Parquet

Improve performance & scalability

ğŸ“‚ Notebook:

notebooks/06_optimization_parquet.ipynb

ğŸŸ¢ STEP 7: Dashboard Data Preparation

Generate KPI tables

Save dashboard-ready outputs

ğŸ“‚ Notebook:

notebooks/07_dashboard_data.ipynb

ğŸ“Š Power BI Dashboard
ğŸ”¹ Dashboard Features

KPI Cards: Total Sales, Profit, Orders, Margin

Regional Sales Performance

Category-wise Profit Contribution

Discount Impact on Profitability

Monthly Sales Trend

Top Revenue-Generating Customers

Interactive slicers (Year, Region, Category)

ğŸ“‚ Power BI File:

powerbi/Retail_Sales_Dashboard.pbix


ğŸ“¸ Preview:

powerbi/dashboard_preview.jpg

ğŸ’¡ Key Business Insights

The West region generates the highest revenue

High discounts significantly reduce profit margins

The technology category is the most profitable

A small group of customers drives a large portion of revenue

Sales show a seasonal decline over time

ğŸ§  Interview-Ready Highlights

Built an end-to-end PySpark ETL pipeline

Implemented window functions for advanced analytics

Optimized big data storage using Parquet

Designed an executive-level Power BI dashboard

Followed proper data engineering & BI layering

ğŸ§¾ Resume Bullet (Use This)

Built an end-to-end retail analytics solution using PySpark and Power BI, performing data cleaning, transformation, business KPI analysis, window functions, and Parquet optimization to deliver executive-level insights.

ğŸš€ How to Run This Project
conda create -n pyspark_env python=3.9
conda activate pyspark_env
pip install pyspark pandas


Run notebooks in order from 01 â†’ 07.

ğŸ Final Note

This project follows industry-standard data engineering and analytics practices and is suitable for Data Analyst, Data Engineer, and Analytics roles.

ğŸ¯ WHAT YOU HAVE NOW

âœ… Complete GitHub project
âœ… Step-by-step learning path
âœ… Industry-ready dashboard
âœ… Interview-ready explanation
âœ… Resume-ready project



Ajay, this is not a tutorial project â€” this is a portfolio-grade professional project.

